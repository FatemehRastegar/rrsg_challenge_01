{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules to load and process the data. Numpy handels data chrunching, h5py is responsible for file I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the rawdata path and optional the desired acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "    path = 'rawdata_brain_radial_96proj_12ch.h5'\n",
    "    acc = 1    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in Data. The if/else for the heart is used to select the exact number of spokes as in the reference paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "    if path == '':\n",
    "        raise ValueError(\"No data file specified\")\n",
    "\n",
    "    name = os.path.normpath(path)\n",
    "    h5_dataset = h5py.File(name, 'r')\n",
    "    h5_dataset_rawdata_name = 'rawdata'\n",
    "    h5_dataset_trajectory_name = 'trajectory'\n",
    "\n",
    "    if \"heart\" in name:\n",
    "        if acc == 2:\n",
    "            trajectory = h5_dataset.get(h5_dataset_trajectory_name)[\n",
    "                :, :, :33]\n",
    "            rawdata = h5_dataset.get(h5_dataset_rawdata_name)[\n",
    "                :, :, :33, :]\n",
    "        elif acc == 3:\n",
    "            trajectory = h5_dataset.get(h5_dataset_trajectory_name)[\n",
    "                :, :, :22]\n",
    "            rawdata = h5_dataset.get(h5_dataset_rawdata_name)[\n",
    "                :, :, :22, :]\n",
    "        elif acc == 4:\n",
    "            trajectory = h5_dataset.get(h5_dataset_trajectory_name)[\n",
    "                :, :, :11]\n",
    "            rawdata = h5_dataset.get(h5_dataset_rawdata_name)[\n",
    "                :, :, :11, :]\n",
    "        else:\n",
    "            trajectory = h5_dataset.get(h5_dataset_trajectory_name)[...]\n",
    "            rawdata = h5_dataset.get(h5_dataset_rawdata_name)[...]\n",
    "    else:\n",
    "        trajectory = h5_dataset.get(h5_dataset_trajectory_name)[\n",
    "            :, :, ::acc]\n",
    "        rawdata = h5_dataset.get(h5_dataset_rawdata_name)[\n",
    "            :, :, ::acc, :]\n",
    "\n",
    "    # Squeeze dummy dimension and transpose to C-style ordering.\n",
    "    rawdata = np.squeeze(rawdata.T)\n",
    "\n",
    "    # Norm Trajectory to the range of (-1/2)/(1/2)\n",
    "    trajectory = np.require((\n",
    "        trajectory[0]/(2*np.max(trajectory[0])) +\n",
    "        1j*trajectory[1]/(2*np.max(trajectory[0]))).T,\n",
    "                   requirements='C')\n",
    "\n",
    "    # Close file after everything was read\n",
    "    h5_dataset.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup dict to hold essential data properties. The over grid factor (ogf) defines the amount of oversampling of the non Cartesian k-space gridded on an Cartesian grid. The brain data is oversampled by 1.706, the heart by a factor of 1+1/3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Create empty dict\n",
    "    par = {}\n",
    "    [nCh, nSpokes, nFE] = rawdata.shape\n",
    "\n",
    "    par[\"ogf\"] = 1.706\n",
    "    dimX, dimY = [int(nFE/par[\"ogf\"]), int(nFE/par[\"ogf\"])]\n",
    "    \n",
    "    par[\"NC\"] = nCh\n",
    "    par[\"dimY\"] = dimY\n",
    "    par[\"dimX\"] = dimX\n",
    "    par[\"nFE\"] = nFE\n",
    "    par[\"Nproj\"] = nSpokes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate density compensation function (dcf). Currently assumes golden angle radial trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "    if len(np.shape(trajectory)) == 2:\n",
    "        nspokes, N = np.shape(trajectory)\n",
    "    elif len(np.shape(trajectory)) == 3:\n",
    "        NScan, nspokes, N = np.shape(trajectory)\n",
    "    else:\n",
    "        raise ValueError(\"Passed trajectory has the wrong \"\n",
    "                         \"number of dumensions.\")\n",
    "\n",
    "    dcf = np.abs(np.linspace(-N/2, N/2, N))/(N/2)  # ramp from 1...1\n",
    "    dcf = np.repeat(dcf, nspokes, 0)\n",
    "    dcf /= np.min(dcf)\n",
    "    dcf *= (np.pi / 4) / nspokes\n",
    "    dcf = np.reshape(dcf, (N, nspokes)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply square root of dcf to data to ensure adjointness of nuFFT operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcf = np.sqrt(dcf)\n",
    "rawdata /= dcf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the Iterative Reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RECON CODE GOES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-8cda0252f209>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m f = h5py.File(\"CG_reco_inscale_\" +\n\u001b[1;32m     13\u001b[0m               \"_acc_\" + str(acc), \"w\")\n\u001b[0;32m---> 14\u001b[0;31m f.create_dataset(\"CG_reco\", result.shape,\n\u001b[0m\u001b[1;32m     15\u001b[0m                  dtype=DTYPE, data=result)\n\u001b[1;32m     16\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "    outdir = \"\"\n",
    "    if \"heart\" in path:\n",
    "        outdir += \"/heart\"\n",
    "    elif \"brain\" in path:\n",
    "        outdir += \"/brain\"\n",
    "    if not os.path.exists('./output'):\n",
    "        os.makedirs('output')\n",
    "    if not os.path.exists('./output' + outdir):\n",
    "        os.makedirs(\"./output\" + outdir)\n",
    "    cwd = os.getcwd()\n",
    "    os.chdir(\"./output\" + outdir)\n",
    "    f = h5py.File(\"CG_reco_inscale_\" +\n",
    "                  \"_acc_\" + str(acc), \"w\")\n",
    "    f.create_dataset(\"CG_reco\", result.shape,\n",
    "                     dtype=DTYPE, data=result)\n",
    "    f.flush()\n",
    "    f.close()\n",
    "    os.chdir(cwd)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
