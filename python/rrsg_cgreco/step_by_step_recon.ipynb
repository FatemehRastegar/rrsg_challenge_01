{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step by step guide for reconstruction of an image\n",
    "\n",
    "Some introduction text about what to expect... Maybe some additional explanation where the data is located, or which packages are needed..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules to load and process the data. Numpy handels data chrunching, h5py is responsible for file I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'goldcomp' from 'rrsg_cgreco._helper_fun' (/home/bugger/PycharmProjects/rrsg_challenge_01/python/rrsg_cgreco/_helper_fun/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-4-2c5e5c5e7135>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mrrsg_cgreco\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrecon\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mrecon\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mrrsg_cgreco\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_helper_fun\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mgoldcomp\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mgoldcomp\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mrrsg_cgreco\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_helper_fun\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mest_coils\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mestimate_coil_sensitivities\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mrrsg_cgreco\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_helper_fun\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcalckbkernel\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mcalculate_keiser_bessel_kernel\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'goldcomp' from 'rrsg_cgreco._helper_fun' (/home/bugger/PycharmProjects/rrsg_challenge_01/python/rrsg_cgreco/_helper_fun/__init__.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import rrsg_cgreco.linop as linop\n",
    "import rrsg_cgreco.solver as solver\n",
    "import rrsg_cgreco.recon as recon\n",
    "\n",
    "from rrsg_cgreco._helper_fun import density_compensation\n",
    "from rrsg_cgreco._helper_fun.est_coils import estimate_coil_sensitivities\n",
    "from rrsg_cgreco._helper_fun.calckbkernel import calculate_keiser_bessel_kernel\n",
    "from rrsg_cgreco._helper_fun.plotfun import plot_complex_arrows, plot_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve a known problem in a difficult space...\n",
    "\n",
    "The simplified signal equation tells us how image space and our acquired data are linked:\n",
    "\n",
    "$$ \\int p(\\vec{r}) \\exp{2\\pi i r k} d\\vec{r} = s(k).$$\n",
    "\n",
    "Since we can discretize this equation, we can also write this as a matrix/vector problem\n",
    "\n",
    "$$ Ax = b. $$\n",
    "\n",
    "However, it might be so that A is an $n\\times m$ matrix, or in any other way not invertible.\n",
    "Multiplying both sides with its transpose gives\n",
    "\n",
    "$$ A^TAx = A^Tb. $$\n",
    "\n",
    "This does give us something to work with. But finding a solution will not be trivial, to\n",
    "aid is in this endaveour, we find the help of the Conjugate Gradient method. This\n",
    "allows us to iteratively find a solution $x$ to this problem.\n",
    "\n",
    "Before we can continue with finding such solution. We first need to modify the data. It\n",
    "is so that we have received raw k-space data that has been sample with a radial trajectory.\n",
    "This causes the Fast Fourier Transform (FFT) to break down. There are possibilities to\n",
    "perform a Non-Uniform Fast Fourier Transform, but it appears that an honest implementation\n",
    "of this will be slow.\n",
    "Thus we embark on a different route: we are going to regrid the radially acquired data to\n",
    "a cartesian grid. The strategy we will use is by extrapolating our data to a cartesian grid\n",
    "with the help of a special convolution kernel: the Keiser Bessel kernel.\n",
    "In addition to that filter, we also need to correct for the density of the sample points with a\n",
    "so called `density compensation function`.\n",
    "After regridding and compensating for the trajectory sampling density, we also need to perform\n",
    "an deapodization filter to compensation for the applied kernel. \n",
    "\n",
    "Let's start!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in data. The if/else for the heart is used to select the exact number of spokes as in the reference paper. Further we rotate and scale the loaded trajectory data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bugger/PycharmProjects/rrsg_challenge_01/python/rrsg_cgreco\n",
      "Shape of the input data (12, 96, 512)\n",
      "Shape of trajectory data (96, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "path = '../../data/rawdata_brain_radial_96proj_12ch.h5'\n",
    "import os\n",
    "print(os.getcwd())\n",
    "undersampling_factor = 1\n",
    "\n",
    "# This gives us normalized trajectory over range -0.5 .. 0.5\n",
    "rawdata, trajectory, noise_scan = recon.read_data(pathtofile=path, undersampling_factor=undersampling_factor)\n",
    "\n",
    "print(f'Shape of the input data {rawdata.shape}')\n",
    "print(f'Shape of trajectory data {trajectory.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To give you an idea what kind of data we just loaded, here a visual representation of the trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quiver plot of the trajectory\n",
    "plot_complex_arrows(trajectory[0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw data contains data of all 12 coils, radially sampled. This pattern is clearly visible due to the bright band through the center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sequence(rawdata[np.newaxis], augm='np.abs');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by showing how one forward iteration of the regridding, deapidzation process looks like\n",
    " \n",
    "First,define parameters for this process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_coils, num_proj, num_reads = rawdata.shape\n",
    "overgridfactor = 2  # over-gridding factor\n",
    "num_scans = 1\n",
    "num_slc = 1\n",
    "dimX, dimY = (int(num_reads/overgridfactor),\n",
    "              int(num_reads/overgridfactor))  # Hoe en waar worden dimX en dimY gebruikt?\n",
    "\n",
    "DTYPE = np.complex64\n",
    "DTYPE_real = np.float32\n",
    "\n",
    "# Put these data points in a dictionary, such that it can be passed around quite easily\n",
    "par_key = ['num_slc', 'num_scans', 'dimX', 'dimY', 'num_coils', 'num_proj', 'num_reads', 'overgridfactor']\n",
    "par_val = [num_slc, num_scans, dimX, dimY, num_coils, num_proj, num_reads, overgridfactor]\n",
    "par = dict(zip(par_key, par_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the density compensation function based on the trajectory data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_comp = (np.sqrt(np.array(density_compensation.get_golden_angle_dcf(trajectory), dtype=DTYPE_real)).astype(DTYPE_real))\n",
    "density_comp = np.require(np.abs(density_comp), DTYPE_real, requirements='C')\n",
    "plt.imshow(density_comp);\n",
    "\n",
    "par['dens_cor'] = density_comp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Bessel Kernel for interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "par['kwidth'] = 5\n",
    "par['klength'] = 500\n",
    "kerneltable, kerneltable_FT, u = calculate_keiser_bessel_kernel(G=256, **par)\n",
    "plt.plot(u, kerneltable);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get apodization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deapodization = 1 / kerneltable_FT.astype(DTYPE_real)\n",
    "deapodization = np.outer(deapodization, deapodization)\n",
    "plt.imshow(deapodization);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have seen all the individual models, we have combined these in a single class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates a NUFFT object\n",
    "import importlib\n",
    "importlib.reload(linop)\n",
    "# TODO make a check for which dimensions the trajectory variable should have\n",
    "NUFFT = linop.NUFFT(par, trajectory, DTYPE=DTYPE, DTYPE_real=DTYPE_real)\n",
    "\n",
    "# TODO make clear which dimensions to use!\n",
    "ogkspace, grid_point_mapping = NUFFT._grid_lut(rawdata[None, :, None], return_mapping=True)\n",
    "\n",
    "# To REALLY see how this mapping happened, check out this graph\n",
    "# Here you see every point that is not equal to zero. We started with an intiialzied matrix of only zeros..\n",
    "# So that means that you now see where the data has been.\n",
    "plot_sequence((np.abs(ogkspace[0, 0:1, 0]) != 0).astype(int));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did this gridding exactly do? Well it created a mapping! \n",
    "\n",
    "it might be strange to see that the original is a rectangle, and the mapping circular.. but remember\n",
    "that one row in the rectangle image represents one spoke of the circular pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This can take some time.. depending on n_step. Here we show how several spokes are being\n",
    "# projected onto the cartesian grid with the help of the gridding kernel\n",
    "fig, ax = plt.subplots(2)\n",
    "len_traj = len(trajectory[0])\n",
    "n_step = len_traj//4\n",
    "import matplotlib.cm\n",
    "cmap = matplotlib.cm.get_cmap('rainbow')\n",
    "\n",
    "for jj in range(0, len_traj, n_step):\n",
    "    for i_color, i_point in enumerate(range(jj * 512, (jj+1)*512, 32)):\n",
    "        for i, temp_point in enumerate(grid_point_mapping[i_point]):\n",
    "            if i == 0:\n",
    "                # Original point\n",
    "                ax[0].scatter(temp_point[0], temp_point[1], color=cmap(i_color + jj));\n",
    "            else:\n",
    "                # Mapped point\n",
    "                ax[1].scatter(temp_point[0], temp_point[1], color=cmap(i_color + jj));\n",
    "\n",
    "ax[0].set_title('Original');\n",
    "ax[1].set_title('Mapping ');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And what is the result of the gridding to the original data...? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sequence(rawdata[np.newaxis], augm='np.real', vmin=(0, 0.000001), ax_off=True);\n",
    "plot_sequence(ogkspace[0:1, :, 0], augm='np.real', vmin=(0, 0.000001), ax_off=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us add a Fourier Transform to it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ogkspace = np.fft.ifftshift(ogkspace, axes=NUFFT.fft_dim)\n",
    "ogkspace = np.fft.ifft2(ogkspace, norm='ortho')\n",
    "ogkspace = np.fft.ifftshift(ogkspace, axes=NUFFT.fft_dim)\n",
    "\n",
    "plot_sequence(ogkspace[0:1, :, 0], augm='np.angle', title='no apodization - angle');\n",
    "plot_sequence(ogkspace[0:1, :, 0], augm='np.abs', title='no apodization - abs');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...AND the apodization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ogkspace_deapo = NUFFT._deapo_adj(ogkspace)\n",
    "\n",
    "plot_sequence(ogkspace_deapo[0:1, :, 0], augm='np.angle', title='with apodization - angle');\n",
    "plot_sequence(ogkspace_deapo[0:1, :, 0], augm='np.abs', title='with apodization - abs');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazing! We moved stuff to a cartesian grid and got ourselves an image!\n",
    " \n",
    "We have now seen how to move from k-space to image space with all the \n",
    "necessary steps involved with radially sampled data. \n",
    "\n",
    "However, we need to also take into account that different coils have a different \n",
    "view on the data. This is expressed in the coil sensitivity. There are various approaches\n",
    " on how to obtain this data. One of them is to apply the ESPIRIT algorithm as is done below. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the coil sensitivities\n",
    "# This adds the 'coils' and 'phase_map' keys to the par dict.\n",
    "estimate_coil_sensitivities(data=rawdata, trajectory=trajectory, par=par)\n",
    "\n",
    "\n",
    "plot_sequence(par['coils'][np.newaxis, :, 0], augm='np.abs');\n",
    "plot_sequence(par['phase_map'], augm='np.angle');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To combine also this (additional) coil information into an operator, and thus \n",
    "make it possible to do some multi coil solution solving, we create a new operator..\n",
    "\n",
    "It has an augmented adjoint and forward operator, based on the `classic` NUFFT operation.\n",
    "But now it included coil information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MRImagingOperator = linop.MRIImagingModel(par, trajectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This operator will be used to solve the Ax=b equation.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgs = solver.CGReco(par)\n",
    "cgs.set_operator(MRImagingOperator)\n",
    "\n",
    "# Init variables\n",
    "maxit = iters = 5\n",
    "lambd = 1e-8\n",
    "tol = 1e-5\n",
    "\n",
    "guess = np.zeros(\n",
    "                (maxit+1, 1, 1,\n",
    "                par['num_slc'],\n",
    "                par['dimY'],\n",
    "                par['dimX']),\n",
    "                dtype=DTYPE)\n",
    "# We start with an initial guess of zero..\n",
    "x = guess\n",
    "data = rawdata * par[\"dens_cor\"]\n",
    "data = data[None, :, None, ...]  # Adjust for some dimensional stuff\n",
    "\n",
    "b = cgs.operator_rhs(data)\n",
    "# Looks decent\n",
    "plt.imshow(np.abs(b[0, 0]))\n",
    "\n",
    "residual = b\n",
    "p = residual\n",
    "delta = np.linalg.norm(residual) ** 2 / np.linalg.norm(b) ** 2\n",
    "res_norm = []\n",
    "res_norm.append(delta)\n",
    "\n",
    "for i in range(iters):\n",
    "    Ax = cgs.operator_lhs(p)\n",
    "    Ax = Ax + lambd * p\n",
    "    alpha = np.vdot(residual, residual) / (np.vdot(p, Ax))\n",
    "    x[i + 1] = x[i] + alpha * p\n",
    "\n",
    "    residual_new = residual - alpha * Ax\n",
    "    delta = np.linalg.norm(residual_new) ** 2 / np.linalg.norm(b) ** 2\n",
    "    res_norm.append(delta)\n",
    "    if delta < tol:\n",
    "        print(\"Converged after %i iterations to %1.3e.\" % (i + 1, delta))\n",
    "        break\n",
    "\n",
    "    if not np.mod(i, 1):\n",
    "        print(\"Residuum at iter %i : %1.3e\" % (i + 1, delta), end='\\r')\n",
    "\n",
    "    beta = (np.vdot(residual_new, residual_new) /\n",
    "            np.vdot(residual, residual))\n",
    "    p = residual_new + beta * p\n",
    "    (residual, residual_new) = (residual_new, residual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sequence(x[-1:, 0, 0, 0], augm='np.abs');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(res_norm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}